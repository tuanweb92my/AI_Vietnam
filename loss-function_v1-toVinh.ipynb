{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hàm loss - Numpy\n",
    "\n",
    "   Máy học bằng phương pháp dùng hàm mất mát(loss). Nó là một phương pháp đánh giá một giải thuật đưa ra tốt đến cỡ nào trong việc mô hình hóa dữ liệu đã cho. Nếu kết quả dự đoán sai lệch quá nhiều so với kết quả thực tế, hàm loss sẽ tạo ra một con số rất lớn. Dần dần, với sự trợ giúp của hàm optimization. Hàm loss học cách giảm lỗi trong việc tiên đoán. Trong bài viết này, chúng tôi sẽ đi qua một số hàm loss và các ứng dụng của chúng trong lĩnh vực máy học và học sâu. Không có hàm loss phù hợp với tất cả các thuật toán trong máy học. Có nhiều yếu tố khác nhau liên quan đến việc chọn hàm loss cho vấn đề cụ thể chẳng hạn như loại thuật toán máy học được chọn, sự dễ dàng tính toán các đạo hàm và ở một mức độ nào đó tỷ lệ phần trăm của các ngoại lệ trong tập dữ liệu...\n",
    "   \n",
    "   Nói chung, các hàm mất có thể được phân thành hai loại chính tùy thuộc vào loại nhiệm vụ học mà chúng ta đang xử lý - mất mát hồi quy (Regression losses) và mất mát phân loại (Classification losses). Trong phân loại, chúng tôi đang cố gắng dự đoán đầu ra từ tập hợp các dữ liệu phân loại hữu hạnliệuu đầu vào, ví dụ : cho tập dữ liệu lớn hình ảnh của các chữ số viết tay, phân loại chúng thành một trong chữ số từ 0-9 . Mặt khác, hồi quy liên quan đến việc dự đoán giá trị liên tục, ví dụ diện tích sàn, số phòng, kích thước phòng, dự đoán giá phòng.\n",
    "\n",
    "\n",
    "## I. Hàm mất mát hồi quy (Regression Losses)\n",
    "### 1. Mean Square Error (sai số toàn phương trung bình) / Quadratic Loss(Hồi Quy Bậc Hai) / L2 Loss\n",
    "\n",
    "Công thức :\n",
    "\n",
    "# $MSE = \\frac{\\sum_{i=1}^{n}\\left ( y - \\hat{y}i \\right )2}{n}$\n",
    "\n",
    "Như trên cho thấy, sai số bình phương trung bình được đo bằng trung bình chênh lệch bình phương giữa các dự đoán và quan sát thực tế. Nó chỉ quan tâm đến độ lớn trung bình của lổi không phân biệt hướng của chúng. Tuy nhiên, do bình phương, các dự đoán khác xa với các giá trị thực tế rất nhiều so với các dự đoán ít sai lệch khác. Nhưng, cộng vào đó, MSE có các thuộc tính toán học tốt giúp tính toán độ dốc dễ dàng hơn.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d is: ['0.00000000', '0.16600000', '0.33300000']\n",
      "p is: ['0.00000000', '0.25400000', '0.99800000']\n",
      "rms error is: 0.3872849941150143\n"
     ]
    }
   ],
   "source": [
    "# Ví dụ 1 : tính mse \n",
    "    \n",
    "import numpy as np\n",
    "\n",
    "y_hat = np.array([0.000, 0.166, 0.333])\n",
    "y_true = np.array([0.000, 0.254, 0.998])\n",
    "\n",
    "def rmse(predictions, targets):\n",
    "    differences = predictions - targets \n",
    "    differences_squared = differences ** 2\n",
    "    mean_of_differences_squared = differences_squared.mean()\n",
    "    rmse_val = np.sqrt(mean_of_differences_squared)\n",
    "    return rmse_val\n",
    "\n",
    "print(\"d is: \" + str([\"%.8f\" % elem for elem in y_hat]))\n",
    "print(\"p is: \" + str([\"%.8f\" % elem for elem in y_true]))\n",
    "\n",
    "rmse_val = rmse(y_hat, y_true)\n",
    "print(\"rms error is: \" + str(rmse_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ví dụ 2 : Tìm sai số bình phương trung bình cho tập hợp các giá trị sau: (43,41), (44,45), (45,49), (46,47), (47,44).\n",
    "\n",
    "Các bước chung để tính sai số bình phương trung bình từ một tập hợp các giá trị X và Y: \n",
    "- Tìm đường hồi quy. \n",
    "- Chèn các giá trị X của bạn vào phương trình hồi quy tuyến tính để tìm các giá trị Y mới (Y\").\n",
    "- Trừ giá trị Y mới từ bản gốc để nhận lỗi. \n",
    "- Bình phương các lỗi. Thêm các lỗi. Tìm giá trị trung bình.\n",
    "\n",
    "Bước 1: Tìm đường hồi quy. Sử dụng <a href=\"http://www.alcula.com/calculators/statistics/linear-regression/\">link này </a> và có dòng hồi quy y = 9.2 + 0.8x.\n",
    "Bước 2: Tìm giá trị Y\" mới\n",
    "9.2 + 0.8(43) = 43.6\n",
    "9.2 + 0.8(44) = 44.4\n",
    "9.2 + 0.8(45) = 45.2\n",
    "9.2 + 0.8(46) = 46\n",
    "9.2 + 0.8(47) = 46.8\n",
    "Bước 3 : Tìm sai số (Y-Y\")\n",
    "41 – 43.6 = -2.6\n",
    "45 – 44.4 = 0.6\n",
    "49 – 45.2 = 3.8\n",
    "47 – 46 = 1\n",
    "44 – 46.8 = -2.8\n",
    "Bước 4 : Bình phương sai số\n",
    "(-2.6)^2 = 6.76\n",
    "(0.6)^2 = 0.36\n",
    "(3.8)^2 = 14.44\n",
    "1^2 = 1\n",
    "(-2.8)^2 = 7.84\n",
    "\n",
    "<img src=\"mean-squared-error-MSE_VD2.png\" width=\"600\">\n",
    "\n",
    "Bước 5: Tổng cac sai số binh phương : 6.76 + 0.36 + 14.44 + 1 + 7.84 = 30.4\n",
    "\n",
    "Bước 6: sai số bình phương trung bình : 30.4 / 5 = 6.08\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Sai số tuyệt đối trung bình (Mean Absolute Error/L1 Loss)\n",
    "\n",
    "Công thức :\n",
    "\n",
    "# $ MAE = \\frac{\\sum_{i=1}^{n}\\left |y - \\hat{y}i \\right |}{n} $\n",
    "\n",
    "Sai số tuyệt đối trung bình được tính bằng trung bình tổng của sự sai khác tuyệt đối giữa các trị dự đoán và các giá trị quan sát thực tế. Giống như MSE, nó cũng tính toán độ lớn của lỗi mà không xem xét hướng của chúng. Không giống như MSE, MAE cần các công cụ phức tạp hơn như lập trình tuyến tính để tính toán độ dốc. Thêm vào đó, MAE mạnh hơn đối với các ngoại lệ vì nó không sử dụng bình phương.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d is: ['0.00000000', '0.16600000', '0.33300000']\n",
      "p is: ['0.00000000', '0.25400000', '0.99800000']\n",
      "mae error is: 0.251\n"
     ]
    }
   ],
   "source": [
    "# Ví dụ : tính mae \n",
    "\n",
    "import numpy as np\n",
    "\n",
    "y_hat = np.array([0.000, 0.166, 0.333])\n",
    "y_true = np.array([0.000, 0.254, 0.998])\n",
    "print(\"d is: \" + str([\"%.8f\" % elem for elem in y_hat]))\n",
    "print(\"p is: \" + str([\"%.8f\" % elem for elem in y_true]))\n",
    "\n",
    "def mae(predictions, targets):\n",
    "    differences = predictions - targets\n",
    "    absolute_differences = np.absolute(differences)\n",
    "    mean_absolute_differences = absolute_differences.mean()\n",
    "    return mean_absolute_differences\n",
    "\n",
    "mae_val = mae(y_hat, y_true)\n",
    "print (\"mae error is: \" + str(mae_val))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ví dụ 2 : Cách tính sai số tuyệt đối trung bình bằng mô hình dự đoán giá vốn của các ngôi nhà với các kích cỡ khác nhau.\n",
    "\n",
    "Chi phí thực tế của nhà ở trong ví dụ này :\n",
    "2 phòng ngủ - $ 200K \n",
    "3 phòng ngủ - $ 300K \n",
    "4 phòng ngủ - $ 400K \n",
    "5 phòng ngủ - $ 500K\n",
    "Chi phí dự đoán - giả định chi phí nhà ở trong ví dụ này :\n",
    "2 phòng ngủ - $ 230K \n",
    "3 phòng ngủ - $ 290K \n",
    "4 phòng ngủ - $ 740K \n",
    "5 phòng ngủ - $ 450K\n",
    "Sai số trung binh : mae = |200 - 230 | + |300 - 290 | + |400-740| + |500 -450| / 4 = $107.5K\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Sai số độ lệch trung bình (Mean Bias Error)\n",
    "\n",
    "Công thứa này ít phổ biến trong lĩnh vực máy học so với các cộng thức ở trên. Nó giống như MSE với sự khác biệt duy nhất là chúng ta không lấy giá trị tuyệt đối. Rõ ràng có một sự cần thiết phải thận trọng vì các lỗi dương và âm có thể triệt tiêu lẫn nhau. Mặc dù nó ít chính xác hơn trong thực tế, nó có thể xác định xem mô hình có sai lệch dương hay âm hay không.\n",
    "\n",
    "Công thức :\n",
    "\n",
    "# $ MBE = \\frac{\\sum_{i=1}^{n}\\left (y - \\hat{y}i \\right )}{n} $\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Hàm mất mát phân loại (Classification Losses)\n",
    "\n",
    "### 1. Hinge Loss (hàm mất mát bản lề) / Multi class SVM Loss\n",
    "\n",
    "Trong máy học, hàm mất mát bản lề là hàm mất mát được sử dụng để huấn luyện các bộ phân loại.\n",
    "Nói một cách đơn giản, điểm số của mẫu đúng phải lớn hơn tổng số điểm của tất cả các mẫu không chính xác theo một số giới hạn an toàn (thường là một). Và do đó, hàm mất mát bản lề được sử dụng để phân loại biên lề tối đa, hầu như được dùng là cho các mô hình SVM (support vector machines - là các mô hình học có giám sát với các thuật toán học liên quan để phân tích dữ liệu được sử dụng để phân loại và phân tích hồi quy). Mặc dù không khác biệt, nhưng nó có chức năng lồi giúp dễ dàng làm việc với các bộ tối ưu lồi thông thường được sử dụng trong lĩnh vực máy học.\n",
    "\n",
    "Công thức :\n",
    "\n",
    "# $ SVM Loss = \\sum_{j\\neq yi}^{ } max(0,s_{j} -s_{yi} +1 )  $\n",
    "\n",
    "Ví dụ : Hãy xem xét một ví dụ có 3 mẫu dữ liệu huấn luyện và ba lớp để dự đoán - Chó, mèo và ngựa. Phía dưới là các giá trị được dự đoán bởi thuật toán của chúng tôi cho từng lớp \n",
    "\n",
    "<img src=\"HingeLoss.jpeg\">\n",
    "\n",
    "Tính toán hàm mất mát biên lề cho cả 3 mẫu huấn luyện :\n",
    "\n",
    "#### 1st training example \n",
    "max(0, (1.49) - (-0.39) + 1) + max(0, (4.21) - (-0.39) + 1)\n",
    "\n",
    "max(0, 2.88) + max(0, 5.6)\n",
    "\n",
    "2.88 + 5.6\n",
    "\n",
    "8.48 (Giá trị lớn chỉ ra sự tiên đoán rất sai)\n",
    "\n",
    "#### 2nd training example\n",
    "max(0, (-4.61) - (3.28)+ 1) + max(0, (1.46) - (3.28)+ 1)\n",
    "\n",
    "max(0, -6.89) + max(0, -0.82)\n",
    "\n",
    "0 + 0\n",
    "\n",
    "0 () tức tiên đoán chích xác )\n",
    "\n",
    "#### 3rd training example\n",
    "max(0, (1.03) - (-2.27)+ 1) + max(0, (-2.37) - (-2.27)+ 1)\n",
    "\n",
    "max(0, 4.3) + max(0, 0.9)\n",
    "\n",
    "4.3 + 0.9\n",
    "\n",
    "5.2 (Giá trị lớn chỉ ra sự tiên đoán rất sai)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Cross Entropy Loss/Negative Log Likelihood\n",
    "\n",
    "Hàm cross entropy loss(log loss) dùng đo lường hiệu suất của mô hình phân loại cho đầu ra là giá trị xác suất trong khoảng từ 0 đến 1. Hàm tăng khi xác suất dự đoán tách khỏi nhãn thực tế. Một mô hình hoàn hảo có log loss bằng 0. Hàm này là được sử dụng phổ biến nhất cho các vấn đề về phân loại. \n",
    "\n",
    "\n",
    "Công thức :\n",
    "\n",
    "# $CrossEntropyLoss = -(y_{i}log(\\hat{y}i)) + (1-y_{i})log(1- \\hat{y}i)) $\n",
    "\n",
    "Lưu ý rằng khi nhãn thực tế là 1 thì (y (i) = 1), nửa vế sau của hàm sẽ biến mất. \n",
    "Trong khi trường hợp nhãn thực tế là 0 (thì y (i) = 0) thì nửa vế đầu bị bỏ đi.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross entropy loss is: 0.7135329699138555\n"
     ]
    }
   ],
   "source": [
    "# Ví dụ : \n",
    "\n",
    "import numpy as np\n",
    "\n",
    "predictions = np.array([[0.25,0.25,0.25,0.25],\n",
    "                        [0.01,0.01,0.01,0.96]])\n",
    "targets = np.array([[0,0,0,1],\n",
    "                    [0,0,0,1]])\n",
    "\n",
    "def cross_entropy(predictions, targets, epsilon=1e-10):\n",
    "    predictions = np.clip(predictions, epsilon, 1. - epsilon)\n",
    "    N = predictions.shape[0]\n",
    "    ce_loss = -np.sum(np.sum(targets * np.log(predictions + 1e-5)))/N\n",
    "    return ce_loss\n",
    "\n",
    "cross_entropy_loss = cross_entropy(predictions, targets)\n",
    "print (\"Cross entropy loss is: \" + str(cross_entropy_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
